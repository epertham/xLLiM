install.packages("~/Documents/postdoc/programmation/package/gllim_1.0.tar.gz",type="source")
library(gllim)
data(responses)
install.packages("~/Documents/postdoc/programmation/package/gllim_1.0.tar.gz",type="source")
library(gllim)
install.packages("~/Documents/postdoc/programmation/package/gllim_1.0.tar.gz",type="source",repos=NULL)
library(gllim)
data(reponses)
data(responses)
data(covariates)
nrmse = sqrt(rowMeans((test.responses-pred)^2))/norm_term
data(responses)
dim(responses) # 2 100
R.version()
R.version
data.test = rbind(trainy)
library(Matrix) #sparseMatrix
library(MASS)
library(abind) #abind
library(corpcor) #is.positive.definite
library(mvtnorm)
library(fields)
library(clusterGeneration)
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/loggausspdf.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/logsumexp.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/emgm.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/gllim.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/gllim_inverse_map.R")
# install.packages("~/Documents/postdoc/programmation/package/gllim_1.0.tar.gz",type="source",repos=NULL)
# library(gllim)
## setting dimensions
L = 2
D = 50
K = 3
## generating model parameters
pik = runif(K)
pik = pik/sum(pik)
ck = matrix(rnorm(L*K),ncol=K,nrow=L)
Gammak = lapply(1:K,function(k){cov2cor(genPositiveDefMat(dim=L,covMethod="unifcorrmat")$Sigma)}) ## list or array?
Ak = lapply(1:K,function(k){matrix(rnorm(L*D),ncol=L,nrow=D)})
bk = matrix(rnorm(D*K),ncol=K,nrow=D)
Sigmak = lapply(1:K,function(k) diag(D))
for (k in 1:K){image.plot(Sigmak[[k]])}
## simulate dataset
n = 100
trainz = sample(1:K,size=n,replace=TRUE,prob=pik) #hidden multinomial variable
trainx = sapply(trainz,function(k){rmvnorm(1,mean=ck[,k],sigma=Gammak[[k]])})
trainy = sapply(1:n,function(i){Ak[[trainz[i]]]%*%trainx[,i] + bk[,trainz[i]] + as.vector(rmvnorm(1,mean=rep(0,D),sigma=Sigmak[[trainz[i]]]))})
data.xllim = rbind(trainx,trainy)
n = 20
trainz = sample(1:K,size=n,replace=TRUE,prob=pik) #hidden multinomial variable
trainx = sapply(trainz,function(k){rmvnorm(1,mean=ck[,k],sigma=Gammak[[k]])})
trainy = sapply(1:n,function(i){Ak[[trainz[i]]]%*%trainx[,i] + bk[,trainz[i]] + as.vector(rmvnorm(1,mean=rep(0,D),sigma=Sigmak[[trainz[i]]]))})
data.test = rbind(trainy)
save(data.xllim ,file="~/Documents/postdoc/programmation/package/xLLiM/data/data.xllim.rda")
save(data.test, file="~/Documents/postdoc/programmation/package/xLLiM/data/data.test.rda")
install.packages("~/Documents/postdoc/programmation/package/xLLiM_1.0.tar.gz", repos = NULL, type = "source")
library(xLLiM)
data(data.xllim)
K=10
r = emgm(data.xllim, init=K, 10, verb=0);
r
names(r)
r$llh
emgm = function(X, init, maxiter=100,verb=0){
# % Perform EM algorithm for fitting the Gaussian mixture model.
# %   X: d x n data matrix
# %   init: k (1 x 1) or posteriors (n x k) or center (d x k)
# % Written in Matlab by Michael Chen (sth4nth@gmail.com)
# % Converted to R by Emeline Perthame (perthame.emeline@gmail.com)
# %% initialization
initialization = function(X, init){
d = nrow(X) ; n = ncol(X);
if (is.list(init))   #% initialize with a model
{R  = expectation(X,init);}
else {
if (length(init) == 1) #% random initialization
{k = init;
idx = sample(1:n,k,replace=FALSE);
m = X[,idx,drop=FALSE];
label = max.col(t(sweep(t(m)%*%X,1,colSums(m^2)/2,"-")))
u = sort(unique(label))
count=0;
while (k != length(u) && count<20){
count=count+1;
k=length(u);
idx = sample(1:n,k,replace=FALSE);
###
m = X[,idx];
m = as.matrix(m);
label = max.col(t(sweep(t(m)%*%X,1,colSums(m^2)/2,"-")))
u = sort(unique(label))
}
k=length(u);
R = as.matrix(sparseMatrix(i=1:n,j=label,x=rep(1,n),dims=c(n,k)))
}
else {
if (nrow(init) == n)
{R = init;}
else {
if (nrow(init) == d)
{k = ncol(init);
m = init;
m = as.matrix(m);
label = max.col(t(sweep(t(m)%*%X,2,colSums(m^2)/2,"-")))
R = as.matrix(sparseMatrix(i=1:n,j=label,x=rep(1,n),dims=c(n,k)))
}
else {stop('ERROR: init is not valid.');}
}
}
}
return(R)
}
expectation = function(X, model){
mu = model$mu;
Sigma = model$Sigma;
w = model$weight;
n = ncol(X);
k = ncol(mu);
logRho = matrix(0,n,k);
for (i in 1:k){
logRho[,i] = loggausspdf(X,mu[,i,drop=FALSE],Sigma[,,i]);
}
logRho = sweep(logRho,2,log(w),"+")
TT = logsumexp(logRho,2);
llh = sum(TT)/n;
logR= sweep(logRho,1,TT,"-")
R = exp(logR);
return(list(R=R, llh=llh))
}
maximization = function(X, R){
d = nrow(X) ; n = ncol(X)
k = ncol(R) ;
nk = colSums(R);
w = nk/n;
mu = sweep(X%*%R,2,1/nk,"*") ### attention risque d'erreur ici
Sigma = array(0,dim=c(d,d,k));
sqrtR = sqrt(R);
for (i in 1:k){
Xo = sweep(X,1,mu[,i],"-")
Xo = sweep(Xo,2,sqrtR[,i],"*")
Sigma[,,i] = tcrossprod(Xo)/nk[i];
#% add a prior for numerical stability
Sigma[,,i] = Sigma[,,i]+diag(d)*(1e-08);
}
return(list(mu=mu,Sigma=Sigma,weight=w))
}
if(verb>=1) print('     EM for Gaussian mixture: running ... ');
R = initialization(X,init);
label = max.col(R)
R = R[,sort(unique(label))];
tol = 1e-14;
llh = rep(-Inf, maxiter)
converged = FALSE;
t = 0;
while (!converged & t < maxiter){
t = t+1;
if(verb>=1) print(paste('     Step ',t,sep=""));
model = maximization(X,as.matrix(R));
tmp = expectation(X,model);
R=tmp$R; llh[t]=tmp$llh
label = max.col(R)
u = unique(label);
if (ncol(R) != length(u))
{ R = R[,u]; } else {converged = ((llh[t+1]-llh[t]) < tol*abs(llh[t+1]));} #% remove empty components
}
if(verb>=1) {
if (converged)
{print(paste('Converged in ',t,' steps.',sep=""));}
else
{print(paste('Did not converge in ',maxiter,' steps.',sep=""));}
}
return(list(label= label, model= model, llh= llh, R=R))
}
r = emgm(data.xllim, init=K, 10, verb=0);
library(SparseM)
r = emgm(data.xllim, init=K, 10, verb=0);
sparseMatrix
?sparseMatrix
library(Matrix)
r = emgm(data.xllim, init=K, 10, verb=0);
install.packages("~/Documents/postdoc/programmation/package/xLLiM_1.0.tar.gz", repos = NULL, type = "source")
library(xLLiM)
r = emgm(data.xllim, init=K, 10, verb=0);
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/loggausspdf.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/logsumexp.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/emgm.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/gllim.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/gllim_inverse_map.R")
r = emgm(data.xllim, init=K, 10, verb=0);
library(Matrix) #sparseMatrix
library(MASS)
library(abind) #abind
library(corpcor) #is.positive.definite
library(mvtnorm)
library(fields)
library(clusterGeneration)
r = emgm(data.xllim, init=K, 10, verb=0);
r
r$llh
r = emgm(data.xllim, init=K, 10, verb=1);
r$llh
emgm = function(X, init, maxiter=100,verb=0){
# % Perform EM algorithm for fitting the Gaussian mixture model.
# %   X: d x n data matrix
# %   init: k (1 x 1) or posteriors (n x k) or center (d x k)
# % Written in Matlab by Michael Chen (sth4nth@gmail.com)
# % Converted to R by Emeline Perthame (perthame.emeline@gmail.com)
# %% initialization
initialization = function(X, init){
d = nrow(X) ; n = ncol(X);
if (is.list(init))   #% initialize with a model
{R  = expectation(X,init);}
else {
if (length(init) == 1) #% random initialization
{k = init;
idx = sample(1:n,k,replace=FALSE);
m = X[,idx,drop=FALSE];
label = max.col(t(sweep(t(m)%*%X,1,colSums(m^2)/2,"-")))
u = sort(unique(label))
count=0;
while (k != length(u) && count<20){
count=count+1;
k=length(u);
idx = sample(1:n,k,replace=FALSE);
###
m = X[,idx];
m = as.matrix(m);
label = max.col(t(sweep(t(m)%*%X,1,colSums(m^2)/2,"-")))
u = sort(unique(label))
}
k=length(u);
R = as.matrix(sparseMatrix(i=1:n,j=label,x=rep(1,n),dims=c(n,k)))
}
else {
if (nrow(init) == n)
{R = init;}
else {
if (nrow(init) == d)
{k = ncol(init);
m = init;
m = as.matrix(m);
label = max.col(t(sweep(t(m)%*%X,2,colSums(m^2)/2,"-")))
R = as.matrix(sparseMatrix(i=1:n,j=label,x=rep(1,n),dims=c(n,k)))
}
else {stop('ERROR: init is not valid.');}
}
}
}
return(R)
}
expectation = function(X, model){
mu = model$mu;
Sigma = model$Sigma;
w = model$weight;
n = ncol(X);
k = ncol(mu);
logRho = matrix(0,n,k);
for (i in 1:k){
logRho[,i] = loggausspdf(X,mu[,i,drop=FALSE],Sigma[,,i]);
}
logRho = sweep(logRho,2,log(w),"+")
TT = logsumexp(logRho,2);
llh = sum(TT)/n;
logR= sweep(logRho,1,TT,"-")
R = exp(logR);
return(list(R=R, llh=llh))
}
maximization = function(X, R){
d = nrow(X) ; n = ncol(X)
k = ncol(R) ;
nk = colSums(R);
w = nk/n;
mu = sweep(X%*%R,2,1/nk,"*") ### attention risque d'erreur ici
Sigma = array(0,dim=c(d,d,k));
sqrtR = sqrt(R);
for (i in 1:k){
Xo = sweep(X,1,mu[,i],"-")
Xo = sweep(Xo,2,sqrtR[,i],"*")
Sigma[,,i] = tcrossprod(Xo)/nk[i];
#% add a prior for numerical stability
Sigma[,,i] = Sigma[,,i]+diag(d)*(1e-08);
}
return(list(mu=mu,Sigma=Sigma,weight=w))
}
if(verb>=1) print('     EM for Gaussian mixture: running ... ');
R = initialization(X,init);
label = max.col(R)
R = R[,sort(unique(label))];
tol = 1e-14;
llh = rep(-Inf, maxiter)
converged = FALSE;
t = 0;
while (!converged & t < maxiter){
t = t+1;
if(verb>=1) print(paste('     Step ',t,sep=""));
model = maximization(X,as.matrix(R));
tmp = expectation(X,model);
R=tmp$R; llh[t]=tmp$llh
label = max.col(R)
u = unique(label);
if (ncol(R) != length(u))
{ R = R[,u]; } else {converged = ((llh[t+1]-llh[t]) < tol*abs(llh[t+1]));} #% remove empty components
}
if(verb>=1) {
if (converged)
{print(paste('Converged in ',t,' steps.',sep=""));}
else
{print(paste('Did not converge in ',maxiter,' steps.',sep=""));}
}
return(list(label= label, model= model, llh= llh[1:t], R=R))
}
r = emgm(data.xllim, init=K, 10, verb=1);
r$llh
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r = emgm(data.xllim, init=K, 10, verb=1);
r$llh
r$model
names(r$model)
sum(r$model$weight)
r$R
dim(r$R)
dim(r$model$Sigma)
dim(r$model$mu)
r$label
remove.packages("xLLiM")
library(xLLim)
library(Matrix) #sparseMatrix
library(MASS)
library(abind) #abind
library(corpcor) #is.positive.definite
library(mvtnorm)
library(fields)
library(clusterGeneration)
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/loggausspdf.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/logsumexp.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/emgm.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/gllim.R")
source("/Users/Emeline/Documents/postdoc/programmation/package/xLLiM/R/gllim_inverse_map.R")
# install.packages("~/Documents/postdoc/programmation/package/gllim_1.0.tar.gz",type="source",repos=NULL)
# library(gllim)
## setting dimensions
L = 1
D = 50
K = 3
## generating model parameters
pik = runif(K)
pik = pik/sum(pik)
ck = matrix(rnorm(L*K),ncol=K,nrow=L)
Gammak = lapply(1:K,function(k){cov2cor(genPositiveDefMat(dim=L,covMethod="unifcorrmat")$Sigma)}) ## list or array?
Ak = lapply(1:K,function(k){matrix(rnorm(L*D),ncol=L,nrow=D)})
bk = matrix(rnorm(D*K),ncol=K,nrow=D)
Sigmak = lapply(1:K,function(k) diag(D))
for (k in 1:K){image.plot(Sigmak[[k]])}
## simulate dataset
n = 100
trainz = sample(1:K,size=n,replace=TRUE,prob=pik) #hidden multinomial variable
trainx = sapply(trainz,function(k){rmvnorm(1,mean=ck[,k],sigma=Gammak[[k]])})
trainy = sapply(1:n,function(i){Ak[[trainz[i]]]%*%trainx[,i] + bk[,trainz[i]] + as.vector(rmvnorm(1,mean=rep(0,D),sigma=Sigmak[[trainz[i]]]))})
ncol(trainy)
?stop
